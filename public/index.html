<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>VoxTalk (Event-Driven Halo)</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="icon" href="data:,">
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <div class="app">
    <p class="demo-label">Event-Driven Halo</p>
    <h1>Talk to VoxTalk</h1>
    <button id="pttBtn" aria-pressed="false"></button>
    <div class="hint">Click to Talk</div>
    <button id="printBtn" class="print-btn">üñ®Ô∏è Print Conversation</button>
    <audio id="remote" autoplay playsinline></audio>
  </div>
  <div id="conversation-panel" style="display:none;">
    <div id="conversation"></div>
  </div>
  <div id="spotlight-card"></div>
  <script>
    const pttBtn = document.getElementById('pttBtn');
    const rtAudio = document.getElementById('remote');
    const printBtn = document.getElementById('printBtn');
    const conversationPanel = document.getElementById('conversation-panel');
    const conversationDiv = document.getElementById('conversation');
    const spotlightCard = document.getElementById('spotlight-card');

    let conversationLines = [];
    let userTranscript = "";
    let aiTranscript = "";
    let listening = false;

    function setAIPulsing(on) {
      if (on) {
        pttBtn.classList.add('speaking');
      } else {
        pttBtn.classList.remove('speaking');
      }
    }

    function printConversation() {
      conversationDiv.innerHTML = "";
      conversationLines.forEach(line => {
        const div = document.createElement("div");
        div.textContent = (line.role === "user" ? "You: " : "VoxTalk: ") + line.text;
        conversationDiv.appendChild(div);
      });
      conversationPanel.style.display = "block";
      setTimeout(() => {
        window.print();
        conversationPanel.style.display = "none";
      }, 250);
    }

    function showProduct(name, price, imageUrl, linkUrl) {
      spotlightCard.innerHTML = `
        <img src="${imageUrl}" alt="${name}">
        <div class="info">
          <h3>${name}</h3>
          <p>Price: ${price}</p>
          <a href="${linkUrl}" target="_blank">View Product</a>
          <a href="${linkUrl}?add-to-cart=1" target="_blank">Add to Cart</a>
        </div>
      `;
      spotlightCard.classList.add("visible");
    }

    let pc = null;
    let micTrack = null;

    // Halo ON when AI audio is playing
    rtAudio.onplaying = () => {
      setAIPulsing(true);
      if (listening) {
        listening = false;
        if (micTrack) micTrack.enabled = false;
        pttBtn.setAttribute('aria-pressed', 'false');
      }
    };
    // Halo OFF when AI audio ends
    rtAudio.onended = () => {
      setAIPulsing(false);
    };

    async function initRealtime() {
      try {
        const s = await fetch("/session", { method:"POST" });
        const { client_secret, model, voice } = await s.json();

        if (pc) {
          pc.close();
          pc = null;
        }

        pc = new RTCPeerConnection();
        const mic = await navigator.mediaDevices.getUserMedia({ audio:true });
        micTrack = mic.getTracks()[0];
        micTrack.enabled = false;
        pc.addTrack(micTrack, mic);

        pc.ontrack = (ev) => {
          rtAudio.srcObject = ev.streams[0];
          rtAudio.play().catch(()=>{});
        };

        const dc = pc.createDataChannel("events");
        dc.onmessage = (e) => {
          try {
            const evt = JSON.parse(e.data);

            // Buffer transcripts for printing only
            if (evt.type === "response.audio_transcript.delta" && evt.delta) {
              userTranscript += evt.delta;
            }
            if (evt.type === "response.message.delta" && evt.delta) {
              aiTranscript += evt.delta.map(d => d.content?.[0]?.text || "").join("");
            }

            // Halo ON when AI starts
            if (evt.type === "response.audio.started") {
              setAIPulsing(true);
            }
            // Halo OFF when AI finishes
            if (evt.type === "response.audio.done" || evt.type === "output_audio_buffer.stopped") {
              setAIPulsing(false);
              if (userTranscript.trim()) {
                conversationLines.push({ role: "user", text: userTranscript.trim() });
                userTranscript = "";
              }
              if (aiTranscript.trim()) {
                conversationLines.push({ role: "ai", text: aiTranscript.trim() });
                aiTranscript = "";
              }
            }
          } catch(err) {
            console.error("Parse error:", e.data, err);
          }
        };

        const offer = await pc.createOffer({ offerToReceiveAudio:true });
        await pc.setLocalDescription(offer);

        const r = await fetch(
          `https://api.openai.com/v1/realtime?model=${encodeURIComponent(model)}&voice=${voice}`,
          {
            method:"POST",
            headers: {
              "Authorization":`Bearer ${client_secret.value}`,
              "Content-Type":"application/sdp"
            },
            body: offer.sdp
          }
        );

        const answer = { type:"answer", sdp: await r.text() };
        await pc.setRemoteDescription(answer);

      } catch(err) {
        console.error("Realtime init failed", err);
      }
    }

    // PTT button logic (User Input Control ONLY)
    pttBtn.onclick = () => {
      listening = !listening;
      if (micTrack) micTrack.enabled = listening;
      if (listening) {
        setAIPulsing(false);
        pttBtn.setAttribute('aria-pressed', 'true');
      } else {
        rtAudio.pause();
        rtAudio.currentTime = 0;
        rtAudio.srcObject = null;
        pttBtn.setAttribute('aria-pressed', 'false');
      }
    };

    printBtn.onclick = printConversation;
    initRealtime();
  </script>
</body>
</html>
