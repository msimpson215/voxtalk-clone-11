<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>VoxTalk (Quiet-Mode Extension)</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="icon" href="data:,">
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <div class="app">
    <p class="demo-label">VoxTalk Mothership Mode</p>
    <h1>Talk to VoxTalk</h1>

    <!-- main talk button -->
    <button id="pttBtn" aria-pressed="false"></button>
    <div class="hint">Click to Talk (Voice Mode)</div>

    <!-- quiet mode input -->
    <div class="quietbar">
      <button id="quietMic" title="Speak quietly">üé§</button>
      <input id="quietInput" type="text" placeholder="Type or speak your question quietly‚Ä¶" />
      <button id="quietSend">Send</button>
    </div>

    <!-- console-style transcript -->
    <div id="status" class="status"></div>

    <audio id="remote" autoplay playsinline></audio>
  </div>

  <button id="printBtn">üñ®Ô∏è Print Conversation</button>

  <script>
    const pttBtn = document.getElementById("pttBtn");
    const rtAudio = document.getElementById("remote");
    const printBtn = document.getElementById("printBtn");
    const statusEl = document.getElementById("status");

    const quietMic = document.getElementById("quietMic");
    const quietInput = document.getElementById("quietInput");
    const quietSend = document.getElementById("quietSend");

    let pc=null, micTrack=null, dc=null;

    // simple console logger
    function log(msg, cls="info"){
      const d=document.createElement("div");
      d.className=cls;
      d.textContent=msg;
      statusEl.appendChild(d);
      statusEl.scrollTop=statusEl.scrollHeight;
      console.log(msg);
    }

    function setSpeaking(on){
      pttBtn.classList.toggle("speaking",on);
    }

    // audio life-cycle
    rtAudio.onplaying=()=>{setSpeaking(true);log("[Audio] playing","ok");};
    const stopHalo=()=>{setSpeaking(true);}; // always-on halo, leave true
    rtAudio.onended=stopHalo; rtAudio.onpause=stopHalo; rtAudio.onemptied=stopHalo;

    // print
    printBtn.onclick=()=>window.print();

    async function initRealtime(){
      try{
        const s=await fetch("/session",{method:"POST"});
        const {client_secret,model,voice}=await s.json();

        pc=new RTCPeerConnection();
        const mic=await navigator.mediaDevices.getUserMedia({audio:true});
        micTrack=mic.getTracks()[0];
        micTrack.enabled=false;
        pc.addTrack(micTrack,mic);

        pc.ontrack=(ev)=>{
          const stream=ev.streams[0];
          rtAudio.srcObject=stream;
          rtAudio.muted=false;
          rtAudio.play().catch(e=>log("[Audio] play() blocked","err"));
        };

        dc=pc.createDataChannel("events");
        dc.onmessage=(e)=>{
          let evt;try{evt=JSON.parse(e.data);}catch{return;}
          if(evt.type==="response.audio.started"){log("[AI] audio started","ok");}
          if(evt.type==="response.audio.done"){log("[AI] audio done","info");}
          if(evt.type==="response.message.delta"&&evt.delta){
            const text=evt.delta.map(d=>d.content?.[0]?.text||"").join("");
            if(text)log("VoxTalk: "+text,"ai");
          }
        };

        const offer=await pc.createOffer({offerToReceiveAudio:true});
        await pc.setLocalDescription(offer);
        const r=await fetch(
          `https://api.openai.com/v1/realtime?model=${encodeURIComponent(model)}&voice=${voice}`,
          {
            method:"POST",
            headers:{
              "Authorization":`Bearer ${client_secret.value}`,
              "Content-Type":"application/sdp"
            },
            body:offer.sdp
          });
        const answer={type:"answer",sdp:await r.text()};
        await pc.setRemoteDescription(answer);
        log("[RTC] connected","ok");
      }catch(err){log("Realtime init failed "+err,"err");}
    }

    // push-to-talk
    let listening=false;
    pttBtn.onclick=()=>{
      listening=!listening;
      if(micTrack)micTrack.enabled=listening;
      log("[Mic] "+(listening?"ON":"OFF"),listening?"ok":"info");
    };

    // quiet-mode send
    quietSend.onclick=()=>{
      const text=quietInput.value.trim();
      if(!text)return;
      log("You(quiet): "+text,"user");
      quietInput.value="";
      if(dc&&dc.readyState==="open"){
        dc.send(JSON.stringify({
          type:"response.create",
          response:{modalities:["text"],instructions:text}
        }));
      }
    };

    // quiet-mode mic
    quietMic.onclick=()=>{
      if(!("webkitSpeechRecognition"in window||"SpeechRecognition"in window)){
        log("SpeechRecognition not supported","err");return;
      }
      const Rec=window.SpeechRecognition||window.webkitSpeechRecognition;
      const rec=new Rec();
      rec.lang="en-US";
      rec.onresult=(e)=>{
        const t=e.results[0][0].transcript;
        quietInput.value=t;
        log("You(quiet-mic): "+t,"user");
        if(dc&&dc.readyState==="open"){
          dc.send(JSON.stringify({
            type:"response.create",
            response:{modalities:["text"],instructions:t}
          }));
        }
      };
      rec.start();
    };

    initRealtime();
  </script>
</body>
</html>
