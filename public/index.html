<script>
  const pttBtn   = document.getElementById('pttBtn');
  const answerEl = document.getElementById('answer');
  const rtAudio  = document.getElementById('remote');

  function appendLine(role, text) {
    if (answerEl.querySelector('.muted')) answerEl.innerHTML = '';
    const div = document.createElement('div');
    div.className = 'line';
    div.innerHTML = `<span class="${role}">${role==='me'?'You:':'AI:'}</span>
                     <span class="text">${text}</span>`;
    answerEl.appendChild(div);
    answerEl.scrollTop = answerEl.scrollHeight;
  }

  function setSpeaking(on) { 
    pttBtn.classList.toggle('speaking', on); 
  }

  let pc = null;
  let micTrack = null;

  async function initRealtime() {
    try {
      const s = await fetch("/session", { method:"POST" });
      const { client_secret, model, voice } = await s.json();

      if (pc) {
        pc.close();
        pc = null;
      }

      pc = new RTCPeerConnection();
      const mic = await navigator.mediaDevices.getUserMedia({ audio:true });
      micTrack = mic.getTracks()[0];
      micTrack.enabled = false;
      pc.addTrack(micTrack, mic);

      pc.ontrack = (ev)=> {
        rtAudio.srcObject = ev.streams[0];
        rtAudio.play().catch(()=>{});
      };

      const dc = pc.createDataChannel("events");
      dc.onmessage = (e)=> {
        try {
          const evt = JSON.parse(e.data);

          // Show AI message in chat
          if (evt.type === "response.message.delta") {
            const chunk = evt.delta.map(d=>d.content?.[0]?.text||"").join("");
            if (chunk) appendLine("ai", chunk);
          }

          // Halo ON: VoxTalk starts speaking
          if (evt.type === "response.audio_transcript.delta") {
            setSpeaking(true);
          }

          // Halo OFF: VoxTalk stops speaking
          if (evt.type === "response.audio.done" || evt.type === "output_audio_buffer.stopped") {
            setSpeaking(false);
          }
        } catch(err) {
          console.error("Parse error:", e.data, err);
        }
      };

      const offer = await pc.createOffer({ offerToReceiveAudio:true });
      await pc.setLocalDescription(offer);

      const r = await fetch(
        `https://api.openai.com/v1/realtime?model=${encodeURIComponent(model)}&voice=${voice}`,
        {
          method:"POST",
          headers: {
            "Authorization":`Bearer ${client_secret.value}`,
            "Content-Type":"application/sdp"
          },
          body: offer.sdp
        }
      );
      const answer = { type:"answer", sdp: await r.text() };
      await pc.setRemoteDescription(answer);

    } catch(err) {
      console.error("Realtime init failed", err);
    }
  }

  let listening = false;
  pttBtn.onclick = () => {
    listening = !listening;
    if (micTrack) micTrack.enabled = listening;
    if (listening) {
      appendLine("me","(Listening...)");
      setSpeaking(false);
    } else {
      setSpeaking(false);
      rtAudio.pause();
      rtAudio.currentTime = 0;
      rtAudio.srcObject = null;
      appendLine("me","(Stopped)");
    }
  };

  // Always (re-)init connection on load
  initRealtime();
</script>
