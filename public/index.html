<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>VoxTalk (Halo Test Build)</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="icon" href="data:,">
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <div class="app">
    <p class="demo-label">VoxTalk Halo Test</p>
    <h1>Talk to VoxTalk</h1>
    <button id="pttBtn" aria-pressed="false"></button>
    <div class="hint">Click to Talk</div>
    <audio id="remote" autoplay playsinline></audio>
  </div>

  <script>
    const pttBtn = document.getElementById("pttBtn");
    const rtAudio = document.getElementById("remote");

    function setSpeaking(on) {
      pttBtn.classList.toggle("speaking", on);
      console.log("[Halo]", on ? "ON" : "OFF");
    }

    // Real audio lifecycle listeners
    rtAudio.onplaying = () => {
      console.log("[Audio] playing");
      setSpeaking(true);
    };
    function stopHalo() {
      console.log("[Audio] stopped/ended");
      setSpeaking(false);
    }
    rtAudio.onpause = stopHalo;
    rtAudio.onended = stopHalo;
    rtAudio.onemptied = stopHalo;

    // Manual halo toggle to verify CSS
    pttBtn.onclick = () => {
      const isActive = pttBtn.classList.toggle("speaking");
      console.log("[Manual toggle]", isActive ? "ON" : "OFF");
    };

    // --- WebRTC / Realtime connection ---
    let pc = null;
    let micTrack = null;

    async function initRealtime() {
      try {
        const s = await fetch("/session", { method: "POST" });
        const { client_secret, model, voice } = await s.json();

        if (pc) {
          pc.close();
          pc = null;
          rtAudio.srcObject = null;
        }

        pc = new RTCPeerConnection();
        const mic = await navigator.mediaDevices.getUserMedia({ audio: true });
        micTrack = mic.getTracks()[0];
        micTrack.enabled = false;
        pc.addTrack(micTrack, mic);

        pc.ontrack = (ev) => {
          rtAudio.srcObject = ev.streams[0];
          rtAudio.play().catch(() => {});
        };

        const dc = pc.createDataChannel("events");
        dc.onmessage = (e) => {
          try {
            const evt = JSON.parse(e.data);
            if (evt.type === "response.audio.started") {
              console.log("[VoxTalk] AI START");
            }
            if (evt.type === "response.audio.done") {
              console.log("[VoxTalk] AI DONE signal (waiting for playback)");
            }
          } catch (err) {
            console.error("Parse error:", e.data, err);
          }
        };

        const offer = await pc.createOffer({ offerToReceiveAudio: true });
        await pc.setLocalDescription(offer);

        const r = await fetch(
          `https://api.openai.com/v1/realtime?model=${encodeURIComponent(model)}&voice=${voice}`,
          {
            method: "POST",
            headers: {
              "Authorization": `Bearer ${client_secret.value}`,
              "Content-Type": "application/sdp"
            },
            body: offer.sdp
          }
        );
        const answer = { type: "answer", sdp: await r.text() };
        await pc.setRemoteDescription(answer);

      } catch (err) {
        console.error("Realtime init failed", err);
      }
    }

    initRealtime();
  </script>
</body>
</html>
